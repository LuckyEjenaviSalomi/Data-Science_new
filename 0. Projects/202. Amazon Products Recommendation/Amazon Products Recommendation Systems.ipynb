{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXQzH0nC5JtP"
   },
   "source": [
    "# **Project: Amazon Product Recommendation System**\n",
    "\n",
    "Welcome to the project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model.\n",
    "\n",
    "--------------\n",
    "## **Context:**\n",
    "--------------\n",
    "\n",
    "Today, information is growing exponentially with volume, velocity and variety throughout the globe. This has lead to information overload, and too many choices for the consumer of any business. It represents a real dilemma for these consumers and they often turn to denial. Recommender Systems are one of the best tools that help recommending products to consumers while they are browsing online. Providing personalized recommendations which is most relevant for the user is what's most likely to keep them engaged and help business.\n",
    "\n",
    "E-commerce websites like Amazon, Walmart, Target and Etsy use different recommendation models to provide personalized suggestions to different users. These companies spend millions of dollars to come up with algorithmic techniques that can provide personalized recommendations to their users.\n",
    "\n",
    "Amazon, for example, is well-known for its accurate selection of recommendations in its online site. Amazon's recommendation system is capable of intelligently analyzing and predicting customers' shopping preferences in order to offer them a list of recommended products. Amazon's recommendation algorithm is therefore a key element in using AI to improve the personalization of its website. For example, one of the baseline recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n",
    "\n",
    "----------------\n",
    "## **Objective:**\n",
    "----------------\n",
    "\n",
    "You are a Data Science Manager at Amazon, and have been given the task of building a recommendation system to recommend products to customers based on their previous ratings for other products. You have a collection of labeled data of Amazon reviews of products. The goal is to extract meaningful insights from the data and build a recommendation system that helps in recommending products to online consumers.\n",
    "\n",
    "-----------------------------\n",
    "## **Dataset:**\n",
    "-----------------------------\n",
    "\n",
    "The Amazon dataset contains the following attributes:\n",
    "\n",
    "- **userId:** Every user identified with a unique id\n",
    "- **productId:** Every product identified with a unique id\n",
    "- **Rating:** The rating of the corresponding product by the corresponding user\n",
    "- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmdPxJ2Q7W7p"
   },
   "source": [
    "**Note:** The code has some user defined functions that will be usefull while making recommendations and measure model performance, you can use these functions or can create your own functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoRfgjS2yekq"
   },
   "source": [
    "Sometimes, the installation of the surprise library, which is used to build recommendation systems, faces issues in Jupyter. To avoid any issues, it is advised to use **Google Colab** for this project.\n",
    "\n",
    "Let's start by mounting the Google drive on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3713,
     "status": "ok",
     "timestamp": 1709520167453,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "GZ0YAszcT4zK",
    "outputId": "7b02da7b-1c4a-4c48-edb2-329535f3cb56"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ibk07-Cyekt"
   },
   "source": [
    "**Installing surprise library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7630,
     "status": "ok",
     "timestamp": 1709520175081,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "05HQoiZYlsbB",
    "outputId": "bcc3fb17-1da2-4f82-e25e-b5325c7f6283"
   },
   "outputs": [],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fIt4jcFIm76"
   },
   "source": [
    "## **Importing the necessary libraries and overview of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520175081,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "jzu2P-TT5JtP"
   },
   "outputs": [],
   "source": [
    "# Basic libraries for numerical manipulations and Analysis of Structured Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnngs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# A dictionary output that does not raise a key error\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrXYJAv95JtP"
   },
   "source": [
    "### **Loading the data**\n",
    "- Import the Dataset\n",
    "- Add column names ['user_id', 'prod_id', 'rating', 'timestamp']\n",
    "- Drop the column timestamp\n",
    "- Copy the data to another DataFrame called **df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 17158,
     "status": "ok",
     "timestamp": 1709520192235,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "JGb-Hk1B5JtP",
    "outputId": "7e480753-979f-46a6-c94d-87f27b109053"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2O4AGRLVX78CQ</td>\n",
       "      <td>B000001ON6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2PM4ZSP28ZXIH</td>\n",
       "      <td>B000001ON6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3ILINPH6XUL6Z</td>\n",
       "      <td>B000001ON6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3F6AY4V6548CL</td>\n",
       "      <td>B000001ON6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2RXG56DPCPC4X</td>\n",
       "      <td>B000001ON6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     prod_id  rating\n",
       "0  A2O4AGRLVX78CQ  B000001ON6     1.0\n",
       "1  A2PM4ZSP28ZXIH  B000001ON6     5.0\n",
       "2  A3ILINPH6XUL6Z  B000001ON6     5.0\n",
       "3  A3F6AY4V6548CL  B000001ON6     5.0\n",
       "4  A2RXG56DPCPC4X  B000001ON6     3.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the file path\n",
    "path = \"https://raw.githubusercontent.com/LuckyEjenaviSalomi/Data-Science_new/refs/heads/main/0.%20Projects/202.%20Amazon%20Products%20Recommendation/ratings_Electronics.csv\"\n",
    "\n",
    "# Read csv into a DataFrame\n",
    "data = pd.read_csv(path, header=None,\n",
    "                  names=['user_id', 'prod_id', 'rating', 'timestamp'])\n",
    "data.drop(\"timestamp\", axis=1, inplace=True) #drop the `timestamp` column\n",
    "df = data.copy() #copy the data\n",
    "data.head() #view the first few rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVQnSG5g_9uX"
   },
   "source": [
    "**As this dataset is very large and has 7,824,482 observations, it is not computationally possible to build a model using this. Moreover, many users have only rated a few products and also some products are rated by very few users. Hence, we can reduce the dataset by considering certain logical assumptions.**\n",
    "\n",
    "Here, we will be taking users who have given at least 50 ratings, and the products that have at least 5 ratings, as when we shop online we prefer to have some number of ratings of a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1709520192236,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "WDAgpBj8LeT-"
   },
   "outputs": [],
   "source": [
    "# Create function to remove rows from data based on minimum rating cut-off\n",
    "def remove_rows_based_on_rating_cutoff(data_, column_name: str, rating_cut_off: int):\n",
    "\n",
    "  \"\"\"\n",
    "  returns data excluding the removed items based on rating cut_off\n",
    "  data_: DataFrame\n",
    "  column_name: column name of focus\n",
    "  rating_cut_off: the minimum interactions required for the item to be included\n",
    "  \"\"\"\n",
    "\n",
    "  column = data_[column_name] # Get the column from the DataFrame\n",
    "\n",
    "  #----Create a dictionary of items based on their number of ratings-------\n",
    "  ratings_count = dict()\n",
    "\n",
    "  for item in column:\n",
    "      # If we already have the item, just add 1 to their rating count\n",
    "      if item in ratings_count:\n",
    "          ratings_count[item] += 1\n",
    "\n",
    "      # Otherwise, set their rating count to 1\n",
    "      else:\n",
    "          ratings_count[item] = 1\n",
    "  #-------------------------------------------------------------------------\n",
    "\n",
    "  #Get items to remove\n",
    "  remove_items = []\n",
    "  for item, num_ratings in ratings_count.items():\n",
    "      if num_ratings < rating_cut_off:\n",
    "          remove_items.append(item)\n",
    "\n",
    "  #-------------------------------------------------------------------------\n",
    "  # remove the items\n",
    "  return data_.loc[ ~ data_[column_name].isin(remove_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22619,
     "status": "ok",
     "timestamp": 1709520214841,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "4_b1NdgyPRcu",
    "outputId": "28a98fd6-8c1a-45e6-9821-680ca8452870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove users based on rating cut-off\n",
    "RATINGS_CUTOFF = 50\n",
    "data = remove_rows_based_on_rating_cutoff(data, 'user_id', RATINGS_CUTOFF)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svoaj5vaLxB9"
   },
   "source": [
    "We are left with 125,871 rows of products after removing user_ids based on RATING_CUTOFF of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1709520214841,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "7I5gE3fWQLKC",
    "outputId": "b14351c5-0afd-4575-f6c0-5a5b04287fbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove products based on rating cut-off\n",
    "RATINGS_CUTOFF = 5\n",
    "df_final = remove_rows_based_on_rating_cutoff(data, 'prod_id', RATINGS_CUTOFF)\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BQwj944L-Wq"
   },
   "source": [
    "We are left with 65,290 rows of products after removing products based on RATING CUTOFF of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1709520215455,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "aL1JZ00o5JtQ",
    "outputId": "c05fdd2e-c4ae-457a-f860-75b769904856"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, prod_id, rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a few rows of the imported dataset\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1709520215455,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "WY1WIKc0Sneu",
    "outputId": "7d1af8fc-960c-418f-99c4-647d6cf2dbfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset was pruned by ~100.0%.\n"
     ]
    }
   ],
   "source": [
    "perc_dataset_reduction = ((df.shape[0] - df_final.shape[0])/df.shape[0])\n",
    "print(f'The dataset was pruned by ~{round(perc_dataset_reduction * 100, 0)}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgbMV5xsSJRR"
   },
   "source": [
    "**Observations**\n",
    "- Pruning the dataset based on rating count cut-off of 50 for users and 5 for products resulted in a much more manageable dataset of 65,290 rows. Consequently, the dataset was pruned by ~99%.\n",
    "- Removing users based on rating cut-off of 50 reduced the dataset from 7,824,482 to 125,871 which was further cut down to 65,290 after removing products based on minimum interactions of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuPoy_XfxhXZ"
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0d0bWeG-sVB"
   },
   "source": [
    "### **Shape of the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyBVTRDTyek0"
   },
   "source": [
    "### **Check the number of rows and columns and provide observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1709520215455,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "fJ4eQKaY5JtQ",
    "outputId": "f09c1a45-3a3e-48e4-d821-0ae7b7e1f50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows and columns and provide observations\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Slp-fgWQ-sVD"
   },
   "source": [
    "**Observations**\n",
    "* There are 65,290 rows and 3 columns in the our pruned dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAMWm0nC-sVF"
   },
   "source": [
    "### **Data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1709520215456,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "SVrgMkye5JtQ",
    "outputId": "bbfb6305-6eda-4938-aae5-e5062052877c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   user_id  0 non-null      object \n",
      " 1   prod_id  0 non-null      object \n",
      " 2   rating   0 non-null      float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Check Data types and provide observations\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4fOE02D-sVF"
   },
   "source": [
    "**Observations**\n",
    "- There `user_id` and `prod_id` columns are both object data types. This is okay as they are just identification label and have no computation value.\n",
    "- The `rating` column is a float instead of an integer. The `rating` column will be converted to `integer` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1709520215456,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "XY9uJ_s8Y3y3",
    "outputId": "48d2fe53-aef3-4a51-a0a3-e0d4b895bbb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   user_id  0 non-null      object\n",
      " 1   prod_id  0 non-null      object\n",
      " 2   rating   0 non-null      int32 \n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Convert the rating column to integer\n",
    "df_final['rating'] = df_final['rating'].astype(int)\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgve3MP-Zauy"
   },
   "source": [
    "From the above data info, the `rating` column has been converted to integer to reflect the rating scale 1 - 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTMpOROT-sVG"
   },
   "source": [
    "### **Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1709520216064,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "vt-VEjMA5JtQ",
    "outputId": "9965af16-0b33-461d-93e5-85a5e3a35adc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    False\n",
       "prod_id    False\n",
       "rating     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values present and provide observations\n",
    "df_final.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMWuBNhI5JtR"
   },
   "source": [
    "**Observations**\n",
    "- There are no missing values in all the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wETrCg48-sVG"
   },
   "source": [
    "### **Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520216065,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "tYm30MXR5JtR",
    "outputId": "9ec04caf-c084-4314-ce1b-fd6d228daf65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating\n",
       "count     0.0\n",
       "mean      NaN\n",
       "std       NaN\n",
       "min       NaN\n",
       "25%       NaN\n",
       "50%       NaN\n",
       "75%       NaN\n",
       "max       NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of 'rating' variable and provide observations\n",
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqW50EIJxhXc"
   },
   "source": [
    "**Observations**\n",
    "* There are products with the lowest rating of 1 and maximum of 5. At 25th percentile, there are at least 75% of the products with rating of more than 4. This indicates that majority of the products received favourable rating.\n",
    "* The products have average rating of ~4. This is indicative of high ratings across the products. This is further evidenced by the median of 5 rating.\n",
    "* The ratings are minimally dispersed as the standard deviation of ~1 suggest. This shows that the ratings are fairly similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywyFrZIf5JtR"
   },
   "source": [
    "### **Checking the rating distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUp92pF8puZj"
   },
   "source": [
    "#### **Plotting the distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1709520217131,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "DnvjnEjDIY29",
    "outputId": "4008ef76-eeb6-42cb-9b39-68bce3631373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [count, %, cum %]\n",
      "Index: []\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m     12\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m111\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39mrating\u001b[38;5;241m.\u001b[39mindex, y\u001b[38;5;241m=\u001b[39mrating[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m], palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpectral\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# show data labels of the bar plot\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ax1\u001b[38;5;241m.\u001b[39mcontainers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\seaborn\\categorical.py:2755\u001b[0m, in \u001b[0;36mbarplot\u001b[1;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge, ci, ax, **kwargs)\u001b[0m\n\u001b[0;32m   2752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlen\u001b[39m:\n\u001b[0;32m   2753\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2755\u001b[0m plotter \u001b[38;5;241m=\u001b[39m _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[0;32m   2756\u001b[0m                       estimator, errorbar, n_boot, units, seed,\n\u001b[0;32m   2757\u001b[0m                       orient, color, palette, saturation,\n\u001b[0;32m   2758\u001b[0m                       width, errcolor, errwidth, capsize, dodge)\n\u001b[0;32m   2760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2761\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\seaborn\\categorical.py:1532\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_variables(x, y, hue, data, orient,\n\u001b[0;32m   1531\u001b[0m                          order, hue_order, units)\n\u001b[1;32m-> 1532\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_statistic(estimator, errorbar, n_boot, seed)\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdodge \u001b[38;5;241m=\u001b[39m dodge\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\seaborn\\categorical.py:707\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_colors\u001b[1;34m(self, color, palette, saturation)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Determine the gray color to use for the lines framing the plot\u001b[39;00m\n\u001b[0;32m    706\u001b[0m light_vals \u001b[38;5;241m=\u001b[39m [rgb_to_hls(\u001b[38;5;241m*\u001b[39mc)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m rgb_colors]\n\u001b[1;32m--> 707\u001b[0m lum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(light_vals) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m.6\u001b[39m\n\u001b[0;32m    708\u001b[0m gray \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mrgb2hex((lum, lum, lum))\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# Assign object attributes\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the value count of rating, the vaue_count % and cummulative %\n",
    "rating = pd.DataFrame({\n",
    "    \"count\": df_final['rating'].value_counts(),\n",
    "    \"%\": round(df_final['rating'].value_counts(normalize=True) * 100, 2)\n",
    "    })\n",
    "rating['cum %'] = rating[\"%\"].cumsum() #cummulative percentage value count\n",
    "print(rating)\n",
    "print()\n",
    "\n",
    "# plot the bar plot\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1 = sns.barplot(x=rating.index, y=rating['count'], palette=\"Spectral\")\n",
    "\n",
    "# show data labels of the bar plot\n",
    "for i in ax1.containers:\n",
    "    ax1.bar_label(i, )\n",
    "\n",
    " # add the line graph for cummulative value count percentage\n",
    "ax2 = ax1.twinx()\n",
    "ax2 = sns.lineplot(x=rating.index, y=rating['cum %'], size_order=rating.index)\n",
    "ax2.grid(False)\n",
    "ax2.set_ylabel(\"Cumm %\", color='b')\n",
    "\n",
    "# set title, x-axis label and y-axis label\n",
    "ax1.set_xlabel('Rating Scale', color='b')\n",
    "ax1.set_ylabel(\"Count\", color='b')\n",
    "plt.title(\"Rating Distribution\", fontsize=12, color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0jONrQv-sVH"
   },
   "source": [
    "**Observations**\n",
    "* More than 93% of the products have at least 3 rating, leaving only ~7% for products rated below 3. This indicates an overall good ratings for the products.\n",
    "* Rating 5 has the highest rating of more than 50% of the dataset, followed by 4, 3, 2 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HefpLdLJxhXd"
   },
   "source": [
    "### **Checking the number of unique users and items in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1709520217132,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "NbSom7195JtR",
    "outputId": "19bb504f-f48f-46fb-e358-e13436a78d4b"
   },
   "outputs": [],
   "source": [
    "# Number of total rows in the data and number of unique user id and product id in the data\n",
    "columns = df_final.select_dtypes(np.object_).columns # Get the column names of user_id and prod_id\n",
    "\n",
    "for col in columns:\n",
    "  print(col)\n",
    "  print(f'Unique Count: {df_final[col].nunique()}')\n",
    "  print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qwgz6CUt-sVI"
   },
   "source": [
    "**Observations**\n",
    "- There are potentially 8,761,060 possible ratings `(cartesian product of unique number of user_ids and prod_ids)`. However, there are just 65,290. This is understandable because not all users had purchased all the products. There are also cases where users do not provide ratings for purchased products.\n",
    "-  On the average, users interacted with more than one product as the number of unique users, which is 1540,  exceed number of unique products 5689. This indicates an average of ~4 products per user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfDnhSS4-sVI"
   },
   "source": [
    "### **Users with the most number of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1709520217706,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "n7MX452q5JtR",
    "outputId": "3804f998-14db-4d42-ab93-87df0b869deb"
   },
   "outputs": [],
   "source": [
    "# Top 10 users based on the number of ratings\n",
    "\n",
    "# Create dataframe of users and value count\n",
    "users = pd.DataFrame({\n",
    "    \"rating_count\": df_final['user_id'].value_counts(),\n",
    "    \"%\": round(df_final['user_id'].value_counts(normalize=True) * 100, 2)\n",
    "    })\n",
    "users.reset_index(inplace=True) #reset index\n",
    "users.rename(columns={'index': 'user_id'}, inplace=True) #rename the index column to user_id\n",
    "top_10_users = users.head(10) #Top 10 users based on number of ratings\n",
    "\n",
    "print(top_10_users['rating_count'].sum(), round(top_10_users['%'].sum(), 2), sep=\", \")\n",
    "top_10_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X2w_jt9-sVI"
   },
   "source": [
    "**Observations**\n",
    "- The top 10 users based on number of rating account for `3.21%` of the total number of ratings.\n",
    "- The user with the highest number of ratings had `295` ratings, while the 10th highest user had `179`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnYTx-Ol-sVg"
   },
   "source": [
    "**Now that we have explored and prepared the data, let's build the first recommendation system.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xYGrGVy5JtS"
   },
   "source": [
    "## **Model 1: Rank Based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1709520217707,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "yxZTj1UPxhXh",
    "outputId": "f7ab3494-a75a-4a55-a882-aba5d548e903",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average rating for each product\n",
    "avg_rating = df_final.groupby('prod_id')['rating'].mean().values #Array of averages\n",
    "\n",
    "# Calculate the count of ratings for each product\n",
    "rating_count = df_final.groupby('prod_id')['rating'].count().values #Array of count\n",
    "\n",
    "# Create a dataframe with calculated average and count of ratings\n",
    "prod_ids = df_final.groupby('prod_id')['rating'].count().index #Array of prod_ids\n",
    "final_rating = pd.DataFrame({\n",
    "    'prod_id': prod_ids, 'avg_rating': avg_rating, 'rating_count': rating_count\n",
    "})\n",
    "\n",
    "# Sort the dataframe by average of ratings in the descending order\n",
    "final_rating = final_rating.sort_values(by='avg_rating', ascending=False)\n",
    "\n",
    "# See the first five records of the \"final_rating\" dataset\n",
    "final_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1709520217707,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "zKU__5s1xhXi"
   },
   "outputs": [],
   "source": [
    "# Defining a function to get the top n products based on the highest average rating and minimum interactions\n",
    "def top_n_products(data, n, min_interaction=100):\n",
    "    \"\"\"\n",
    "    returns top n products based on minimum interations\n",
    "    data: dataframe\n",
    "    n: top number of products to return\n",
    "    min_interactions: minimum number of rating counts a product should have\n",
    "    \"\"\"\n",
    "\n",
    "    # Finding products with minimum number of interactions\n",
    "    recommendations = data[data['rating_count'] > min_interaction]\n",
    "\n",
    "    #  Sorting values with respect to average rating\n",
    "    recommendations = recommendations.sort_values(by='avg_rating', ascending=False)\n",
    "\n",
    "    return recommendations.prod_id.iloc[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1709520217707,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "I-iwTynR_JZO"
   },
   "outputs": [],
   "source": [
    "# Create function to print out top n products\n",
    "def display_top_n_products(final_rating_, n, min_interaction=100):\n",
    "  \"\"\"\n",
    "  prints out top n product to the console\n",
    "  final_rating: final_rating dataframe\n",
    "  n: top n\n",
    "  min_interaction: minimum user-item interactions\n",
    "  \"\"\"\n",
    "\n",
    "  print(f\"Top {n} products with {min_interaction} minimum interations:\")\n",
    "  print(\"-\" * 20)\n",
    "\n",
    "  top_products = top_n_products(final_rating_, n, min_interaction).to_list()\n",
    "\n",
    "  for i, prod in enumerate(top_products):\n",
    "    print(f\"{i + 1}. {prod}\")\n",
    "  print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8l6373PxhXi"
   },
   "source": [
    "### **Recommending top 5 products with 50 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1709520217707,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "7mmn7al--kF-",
    "outputId": "bda3412e-3890-4195-a4ea-06ad2af413da"
   },
   "outputs": [],
   "source": [
    "display_top_n_products(final_rating, 5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9_xW_UMxhXj"
   },
   "source": [
    "### **Recommending top 5 products with 100 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1709520217707,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "dZgGZCUoxhXj",
    "outputId": "12a318d2-98cb-46bb-d486-9c4eda1f44e9"
   },
   "outputs": [],
   "source": [
    "display_top_n_products(final_rating, 5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL-m68a15JtT",
    "outputId": "69132b0f-8d3f-4798-f6a0-249e17a3c822"
   },
   "source": [
    "We have recommended the **top 5** products by using the popularity recommendation system. Now, let's build a recommendation system using **collaborative filtering.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJI5kiiGvOOK"
   },
   "source": [
    "## **Model 2: Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skzc0N1_nVNB"
   },
   "source": [
    "### **Building a baseline user-user similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Uo_MYMnVNB"
   },
   "source": [
    "- Below, we are building **similarity-based recommendation systems** using `cosine` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.  \n",
    "- We will be using a new library, called `surprise`, to build the remaining models. Let's first import the necessary classes and functions from this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520217707,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "UJ1wEylUpexj"
   },
   "outputs": [],
   "source": [
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# Class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# For tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# For splitting the rating data in train and test datasets\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# For implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# For implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# for implementing K-Fold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54MqVAtDTsnl"
   },
   "source": [
    "**Before building the recommendation systems, let's  go over some basic terminologies we are going to use:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qsxb3xhnTsnl"
   },
   "source": [
    "**Relevant item:** An item (product in this case) that is actually **rated higher than the threshold rating** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  \n",
    "\n",
    "**Recommended item:** An item that's **predicted rating is higher than the threshold is a recommended item**, if the **predicted rating is below the threshold then that product will not be recommended to the user**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyLUHCuTsnl"
   },
   "source": [
    "**False Negative (FN):** It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider**, which they would like to minimize.\n",
    "\n",
    "**False Positive (FP):** It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider**, which they would also like to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yuvc2VaZTsnl"
   },
   "source": [
    "**Recall:** It is the **fraction of actually relevant items that are recommended to the user**, i.e., if out of 10 relevant products, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**Precision:** It is the **fraction of recommended items that are relevant actually**, i.e., if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NLc36Y8Tsnm"
   },
   "source": [
    "**While making a recommendation system, it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are some most used performance metrics used in the assessment of recommendation systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqF8fRBqTsnm"
   },
   "source": [
    "### **Precision@k, Recall@ k, and F1-score@k**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imMJNF0HTsnm"
   },
   "source": [
    "**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. The value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
    "\n",
    "\n",
    "**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.\n",
    "\n",
    "**F1-score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBW4BUhWTsnm"
   },
   "source": [
    "### **Some useful functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOBHKh0eTsnm"
   },
   "source": [
    "- Below function takes the **recommendation model** as input and gives the **precision@k, recall@k, and F1-score@k** for that model.  \n",
    "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user.\n",
    "- We will use the precision and recall to compute the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520217707,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "Rxn-GahOTsnm"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(model, testset, k=10, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Return precision and recall at k metrics for each user\n",
    "    model: the model applied\n",
    "    testset: test dataset\n",
    "    k = maximum number of nearest neighbours\n",
    "    threshold: minimum rating\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user\n",
    "    user_est_true = defaultdict(list)\n",
    "\n",
    "    # Making predictions on the test data\n",
    "    predictions = model.test(testset)\n",
    "\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key = lambda x: x[0], reverse = True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    # Mean of all the predicted precisions are calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
    "\n",
    "    # Mean of all the predicted recalls are calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
    "\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    metrics = dict()\n",
    "    metrics['Precision'] = precision  # Overall precion\n",
    "    metrics['Recall'] = recall # Overall recall\n",
    "    metrics['F_1 score'] = round((2*precision*recall)/(precision+recall), 3) #Overall F1 score\n",
    "\n",
    "    print(metrics) #return dictionary of the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZmsamDVyek-"
   },
   "source": [
    "**Hints:**\n",
    "\n",
    "- To compute **precision and recall**, a **threshold of 3.5 and k value of 10 can be considered for the recommended and relevant ratings**.\n",
    "- Think about the performance metric to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hxjJMTwnVNB"
   },
   "source": [
    "Below we are loading the **`rating` dataset**, which is a **pandas DataFrame**, into a **different format called `surprise.dataset.DatasetAutoFolds`**, which is required by this library. To do this, we will be **using the classes `Reader` and `Dataset`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2141,
     "status": "ok",
     "timestamp": 1709520219843,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "rGfYDiOCpe4X"
   },
   "outputs": [],
   "source": [
    "# Instantiating Reader scale with expected rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Loading the rating dataset\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Splitting the data into train and test dataset\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmHTEt7TnVNC"
   },
   "source": [
    "Now, we are **ready to build the first baseline similarity-based recommendation system** using the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVDfVHB4tQfU"
   },
   "source": [
    "### **Building the user-user Similarity-based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1709520220500,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "vO3FL7iape8A",
    "outputId": "68bef436-7e09-4c8f-9c5f-54e79d6fcee9"
   },
   "outputs": [],
   "source": [
    "# Declaring the similarity options\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True}\n",
    "\n",
    "# Initialize the KNNBasic model using sim_options declared, Verbose = False, and setting random_state = 1\n",
    "algo_knn_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "algo_knn_user.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above\n",
    "precision_recall_at_k(algo_knn_user, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEuJK_A9Tsnn"
   },
   "source": [
    "**Observations**\n",
    "- We can observe that the baseline model has `RMSE=1.039` on the test set.\n",
    "- Intuition of Recall - We are getting a **recall of ~0.785**, which means out of **all the relevant products, 78.5% are recommended**.\n",
    "- Intuition of Precision - We are getting a **precision of ~ 0.852**, which means **out of all the recommended products, 85.2% are relevant**.\n",
    "- Here **F_1 score** of the **baseline model is ~0.82**. It indicates that **mostly recommended products were relevant and relevant products were recommended**. We can try to improve the performance by using **GridSearchCV to tune different hyperparameters** of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reFD0-nsnVNC"
   },
   "source": [
    "Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and `productId=1400501466`** as shown below. Here the user has already interacted or watched the product with productId '1400501466' and given a rating of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1709520220501,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "Sxd23bZ9pe_x",
    "outputId": "680e013e-f85f-4dcc-8d38-a9157308ceee"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "user_id, prod_id, r_ui = \"A3LDPF5FMB782Z\", \"1400501466\", 5\n",
    "\n",
    "algo_knn_user.predict(user_id, prod_id, r_ui=r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJcqG_wemRH"
   },
   "source": [
    "- The actual rating for this user-product pair is 5 and predicted rating is 3.00 by this similarity based baseline model, which is a bit good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj6ecbglTsno"
   },
   "source": [
    "Below is the **list of users who have not seen the product with product id \"1400501466\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1709520220501,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "xCRBMD-RTsno",
    "outputId": "f79b79b3-58a3-4247-fc95-25b33b05c540"
   },
   "outputs": [],
   "source": [
    "# Find unique user_id where prod_id is not equal to \"1400501466\"\n",
    "prod_id = \"1400501466\"\n",
    "\n",
    "print(f\"Unique user_ids where prod_id is not equal to {prod_id}:\")\n",
    "print(\"-\" * 20)\n",
    "print(df_final.loc[df_final['prod_id'] != prod_id]['user_id'].unique())\n",
    "print(\"-\" * 20)\n",
    "print()\n",
    "\n",
    "user_id = \"A34BZM6S9L7QI4\"\n",
    "print(f\"Is user_id '{user_id}' in the above list? {user_id in df_final.loc[df_final['prod_id'] != prod_id]['user_id'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT42ecaSTsno"
   },
   "source": [
    "* It can be observed from the above list that **user \"A34BZM6S9L7QI4\" has not seen the product with productId \"1400501466\"** as this userId is a part of the above list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXSgq8OEnVNE"
   },
   "source": [
    "**Below we are predicting rating for `userId=A34BZM6S9L7QI4` and `prod_id=1400501466`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520220501,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "PbFcBj1PpfEV",
    "outputId": "c8ebe714-55db-42c7-8fd6-79907fc8c1c8"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with a non interacted product\n",
    "prod_id = \"1400501466\"\n",
    "user_id = \"A34BZM6S9L7QI4\"\n",
    "\n",
    "algo_knn_user.predict(user_id, prod_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02rwld8yemRI"
   },
   "source": [
    "**Observations**\n",
    "* The user-user similarity base model predicted a rating of ~4.29 for the user `A34BZM6S9L7QI4` and prod_id `1400501466`.\n",
    "* The product has not been seen by the user and it appears to fall within the mean rating range.\n",
    "* The model will be hyperparameter-tuned to make it better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejjof6csnVNF"
   },
   "source": [
    "### **Improving similarity-based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2j4VvfQnVNF"
   },
   "source": [
    "Below, we will be tuning hyperparameters for the `KNNBasic` algorithm. Let's try to understand some of the hyperparameters of the KNNBasic algorithm:\n",
    "\n",
    "- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
    "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
    "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise -\n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - Pearson\n",
    "    - Pearson baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40390,
     "status": "ok",
     "timestamp": 1709520260887,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "9LmPbSUSTsnp",
    "outputId": "2e82bdad-54c2-4327-9edb-0a02899e1901"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [20, 30, 40], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'user_based': [True]}\n",
    "              }\n",
    "\n",
    "# Performing 3-fold cross-validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "best_params = gs.best_params['rmse'] # store in variable for re-use\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2fHNvu7nVNF"
   },
   "source": [
    "Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHWgxu_YnVNG"
   },
   "source": [
    "Now, let's build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1875,
     "status": "ok",
     "timestamp": 1709520262751,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "PujRJA8X_JEJ",
    "outputId": "f64df9b2-5850-4a32-af8c-088d1f41f127"
   },
   "outputs": [],
   "source": [
    "# Using the optimal similarity measure for user-user based collaborative filtering\n",
    "k = best_params['k'] # extracted from the best_param dict\n",
    "min_k = best_params['min_k'] # extracted from the best_param dict\n",
    "sim_options = best_params['sim_options'] # extracted from the best_param dict\n",
    "\n",
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "algo_knn_user_optimized = KNNBasic(k=k, min_k=min_k, sim_options=sim_options, verbose=False)\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "algo_knn_user_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k also with k =10\n",
    "print(\"Based Model Metrics:\")\n",
    "precision_recall_at_k(algo_knn_user, testset=testset)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"Optimized Model Metrics:\")\n",
    "precision_recall_at_k(algo_knn_user_optimized, testset=testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHsWvFjKTsnp"
   },
   "source": [
    "**Observations**\n",
    "- After tuning hyperparameters, RMSE for the test set has reduced from 1.04 to 0.98.\n",
    "- It is clear that after tuning the hyperparameters, the tuned model's F-1 score increased from 0.817 to 0.825 in comparison to the baseline model. As a result, we can say that the model's performance has improved after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhcAXK0CnVNG"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520262751,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "FgV63lHiq1TV",
    "outputId": "f86624d0-60f5-47fd-b8df-9d1edfcce0ac"
   },
   "outputs": [],
   "source": [
    "# Use sim_user_user_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId 1400501466\n",
    "user_id, prod_id, r_ui = \"A3LDPF5FMB782Z\", \"1400501466\", 5\n",
    "algo_knn_user_optimized.predict(user_id, prod_id, r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1709520262752,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "HXO2Ztjhq1bN",
    "outputId": "a433e563-4d3e-4fb3-c630-a1b61f3798fa"
   },
   "outputs": [],
   "source": [
    "# Use sim_user_user_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "user_id, prod_id = \"A34BZM6S9L7QI4\", \"1400501466\"\n",
    "algo_knn_user_optimized.predict(user_id, prod_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5i-OPprNF2e"
   },
   "source": [
    "**Observations**\n",
    "- The optimized user-user similarity model improved the rating on the test data and unseen data.\n",
    "- It improved the user rating from 3 to 4.3 on the test data and from 4.29 to 4.30 on uninteracted product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_zwO_FnVNH"
   },
   "source": [
    "### **Identifying similar users to a given user (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2QsfqhanVNH"
   },
   "source": [
    "We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below, we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1709520263313,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "TbFle7cKmBJG",
    "outputId": "9d379890-92a8-4538-8730-e0c968951559"
   },
   "outputs": [],
   "source": [
    "# 0 is the inner id of the above user\n",
    "algo_knn_user_optimized.get_neighbors(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0NsrX_anVNH"
   },
   "source": [
    "### **Implementing the recommendation algorithm based on optimized KNNBasic model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ESobDynVNI"
   },
   "source": [
    "Below we will be implementing a function where the input parameters are:\n",
    "\n",
    "- data: A **rating** dataset\n",
    "- user_id: A user id **against which we want the recommendations**\n",
    "- top_n: The **number of products we want to recommend**\n",
    "- algo: the algorithm we want to use **for predicting the ratings**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1709520263314,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "vW9V1Tk65HlY"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "\n",
    "    # Creating an empty list to store the recommended product ids\n",
    "    recommendations = []\n",
    "\n",
    "    # Creating a user item interactions matrix\n",
    "    user_item_interactions_matrix = data.pivot(index = 'user_id', columns = 'prod_id', values = 'rating')\n",
    "\n",
    "    # Extracting those product ids which the user_id has not interacted yet\n",
    "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "\n",
    "    # Looping through each of the product ids which user_id has not interacted yet\n",
    "    for item_id in non_interacted_products:\n",
    "\n",
    "        # Predicting the ratings for those non interacted product ids by this user\n",
    "        est = algo.predict(user_id, item_id).est\n",
    "\n",
    "        # Appending the predicted ratings\n",
    "        recommendations.append((item_id, est))\n",
    "\n",
    "    # Sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    return recommendations[:top_n] # Returing top n highest predicted rating products for this user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj_S7kh4nVNI"
   },
   "source": [
    "**Predicting top 5 products for userId = \"A3LDPF5FMB782Z\" with similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520263314,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "qWbR85mI5Hrk"
   },
   "outputs": [],
   "source": [
    "# Making top 5 recommendations for user_id \"A3LDPF5FMB782Z\" with a similarity-based recommendation engine\n",
    "user_id, n = \"A3LDPF5FMB782Z\", 5 # user_id and top n products\n",
    "recommendations = get_recommendations(df_final, user_id, n, algo_knn_user_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709520263314,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "b5WfIX0Z6_q2",
    "outputId": "fe90ca8b-8469-40a4-f974-5fd129f1c08f"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(recommendations, columns=['prod_id', 'predicted_ratings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgbzJKk7Tsnr"
   },
   "source": [
    "### **Item-Item Similarity-based Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTJu_2hcTsnr"
   },
   "source": [
    "* Above we have seen **similarity-based collaborative filtering** where similarity is calculated **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between items**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4179,
     "status": "ok",
     "timestamp": 1709520267488,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "W5RMcdzjTsns",
    "outputId": "e80c1135-b4c9-4bd6-d75f-45aaf37ff397"
   },
   "outputs": [],
   "source": [
    "# Declaring the similarity options\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    'user_based': False\n",
    "}\n",
    "\n",
    "# KNN algorithm is used to find desired similar items. Use random_state=1\n",
    "algo_knn_item = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the test set\n",
    "algo_knn_item.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k = 10\n",
    "precision_recall_at_k(algo_knn_item, testset=testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni9LoeUVTsns"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- We can observe that the baseline model has `RMSE=1.03` and `F_1 Score=0.799`on the test set.\n",
    "- We can try to improve the performance number by using `GridSearchCV` to tune different hyperparameters of this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFbcDQmxTsns"
   },
   "source": [
    "Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z` and `prod_Id = 1400501466`** as shown below. Here the user has already interacted or watched the product with productId \"1400501466\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1709520267488,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "JsF-aaWYTsns",
    "outputId": "26ba9c17-2fe0-4a57-a2ef-0f6ad86e82bb"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "user_id, prod_id, r_ui = \"A3LDPF5FMB782Z\", \"1400501466\", 5\n",
    "algo_knn_user.predict(user_id, prod_id, r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h0OyDMFTsns"
   },
   "source": [
    "**Observations**\n",
    "- The item-item similarity base model produced an estimated rating of 3.80 against an actual of 5.00\n",
    "- The base model will be hyperparameter tuned to explore possible improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqKGZoAtTsns"
   },
   "source": [
    "Below we are **predicting rating for the `userId = A34BZM6S9L7QI4` and `prod_id = 1400501466`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1709520267489,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "5yILOxXRTsns",
    "outputId": "b2e06ab1-93b7-48cf-d218-a7eca9c1e075"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with a non interacted product\n",
    "user_id, prod_id = \"A34BZM6S9L7QI4\", \"1400501466\"\n",
    "algo_knn_item.predict(user_id, prod_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDKaAveJTsns"
   },
   "source": [
    "**Observations**\n",
    "- The item-item similarity base model produced an estimated rating of 4.00 on a product the user has not interacted with.\n",
    "- The base model will be hyperparameter-tuned to explore possible improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meSvpNLj_EjD"
   },
   "source": [
    "### **Hyperparameter tuning the item-item similarity-based model**\n",
    "- Use the following values for the param_grid and tune the model.\n",
    "  - 'k': [10, 20, 30]\n",
    "  - 'min_k': [3, 6, 9]\n",
    "  - 'sim_options': {'name': ['msd', 'cosine']\n",
    "  - 'user_based': [False]\n",
    "- Use GridSearchCV() to tune the model using the 'rmse' measure\n",
    "- Print the best score and best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182407,
     "status": "ok",
     "timestamp": 1709520449885,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "f5bcZ3HgTsnt",
    "outputId": "0b35ae48-2b34-4e15-8df6-2ab1b18fc1c0"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30],\n",
    "    'min_k': [3, 6, 9],\n",
    "    'sim_options': {'name': ['msd', 'cosine'],\n",
    "                    'user_based': [False]}\n",
    "  }\n",
    "\n",
    "# Performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "# Fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Find the best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "best_params = gs.best_params['rmse'] # store in variable for re-use\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1psOlx6zTsnt"
   },
   "source": [
    "Once the **grid search** is complete, we can get the **optimal values for each of those hyperparameters as shown above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrSTaQemTsnt"
   },
   "source": [
    "Now let's build the **final model** by using **tuned values of the hyperparameters** which we received by using grid search cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOS9Dwnd_LN6"
   },
   "source": [
    "### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1709520454665,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "dSeiM1qeTsnt",
    "outputId": "6f24a4a6-3b88-4d9a-f9ac-998b215e8a6d"
   },
   "outputs": [],
   "source": [
    "# Using the optimal similarity measure for item-item based collaborative filtering\n",
    "k = best_params['k'] # extracted from the best_param dict\n",
    "min_k = best_params['min_k'] # extracted from the best_param dict\n",
    "sim_options = best_params['sim_options'] # extracted from the best_param dict\n",
    "\n",
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "algo_knn_item_optimized = KNNBasic(k, min_k, sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "algo_knn_item_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k, f1_score and RMSE\n",
    "print(\"Base model metrics:\")\n",
    "precision_recall_at_k(algo_knn_item, testset=testset)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"Optimized model metrics:\")\n",
    "precision_recall_at_k(algo_knn_item_optimized, testset=testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCXKnMI8Tsnt"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- After tuning the hyperparameters, RMSE for the test set has reduced from 1.0345 to 0.9804.\n",
    "- It can be observed that after tuning the hyperparameters, the tuned model's F-1 score increased from 0.799 to 0.816 in comparison to the baseline model. As a result, we can say that the model's performance has improved after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbcj_H94Tsnt"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1709520454665,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "gIBRRvdoTsnt",
    "outputId": "9ce36e09-cbed-4e10-aead-437eb77733db"
   },
   "outputs": [],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "user_id, prod_id, r_ui = \"A3LDPF5FMB782Z\", \"1400501466\", 5\n",
    "\n",
    "algo_knn_item_optimized.predict(user_id, prod_id, r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1709520454665,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "0xPGneo4vSHB",
    "outputId": "1fce184f-7499-4c77-f3d8-b63f0036b68c"
   },
   "outputs": [],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "user_id, prod_id, r_ui = \"A34BZM6S9L7QI4\", \"1400501466\", None\n",
    "\n",
    "algo_knn_item_optimized.predict(user_id, prod_id, r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-0TT7qBvSHC"
   },
   "source": [
    "**Observations**\n",
    "- After hyperparameter tuning, the predictions improved the rating for users under the scenario of a user who had interacted with a product and a user who had not interacted with a product.\n",
    "- For the first scenario, it improved from 3.8 to 4.53 and for the second, it improved from 4.00 to 4.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDlNB7tnTsnu"
   },
   "source": [
    "### **Identifying similar items to a given item (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLdDiFA6Tsnu"
   },
   "source": [
    "We can also find out **similar items** to a given item or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding the 5 most similar items to the item with internal id 0 based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1709520454665,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "ZRJS4oDFTsnu",
    "outputId": "2bb64ffe-7122-49c4-dc74-689a51960525"
   },
   "outputs": [],
   "source": [
    "algo_knn_item_optimized.get_neighbors(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x15IJrYGvSHC"
   },
   "source": [
    "**Predicting top 5 products for userId = \"A1A5KUIIIHFF4U\" with similarity based recommendation system.**\n",
    "\n",
    "**Hint:** Use the get_recommendations() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709520454665,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "rzoEbuZFTsnu"
   },
   "outputs": [],
   "source": [
    "# Making top 5 recommendations for user_id A1A5KUIIIHFF4U with similarity-based recommendation engine.\n",
    "user_id, n = \"A1A5KUIIIHFF4U\", 5 # user_id and top n\n",
    "recommendations = get_recommendations(df_final, user_id, n, algo_knn_item_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1709520454665,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "_kXVTiysTsnv",
    "outputId": "2a2c3571-31c2-460c-a4e1-167a3b923be6"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(recommendations, columns=['prod_id', 'predicted_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHzmYvs0Tsnv"
   },
   "source": [
    "Now as we have seen **similarity-based collaborative filtering algorithms**, let us now get into **model-based collaborative filtering algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKgJpSA9vOOL"
   },
   "source": [
    "## **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF6ZGyqhCAob"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Otha8ovOOL"
   },
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sGl3QkLvOOL"
   },
   "source": [
    "SVD is used to **compute the latent features** from the **user-item matrix**. But SVD does not work when we **miss values** in the **user-item matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4224,
     "status": "ok",
     "timestamp": 1709520458877,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "07-2PT5Ssjqm",
    "outputId": "486748e5-5dd6-41c5-90f7-30416c3f9d9f"
   },
   "outputs": [],
   "source": [
    "# Using SVD matrix factorization. Use random_state = 1\n",
    "algo_svd = SVD(random_state=1)\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "algo_svd.fit(trainset)\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "\n",
    "# print out the metrics for the optimized similarity-based models\n",
    "print(\"Metrics for Optimized user-user similarity model:\")\n",
    "precision_recall_at_k(algo_knn_user_optimized, testset)\n",
    "print(\"-\" * 20)\n",
    "print()\n",
    "\n",
    "print(\"Metrics for Optimized item-item similarity model:\")\n",
    "precision_recall_at_k(algo_knn_item_optimized, testset)\n",
    "print(\"-\" * 20)\n",
    "print()\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# display the metrics for the svd base model\n",
    "print(\"Metrics for svd base model:\")\n",
    "precision_recall_at_k(algo_svd, testset=testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6fTuCDnVNL"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- The **baseline F_1 score** of 0.827 for the matrix factorization model on the test set is higher in comparison to the optimized F_1 score for the user-user (0.825) and the baseline model.\n",
    "- The result for the baseline SVD is better than both baseline and optimized item-item similarity-based recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPRsyizvvSHD"
   },
   "source": [
    "**Let's now predict the rating for a user with `userId = \"A3LDPF5FMB782Z\"` and `prod_id = \"1400501466`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1709520458877,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "yWIhfdxXsjqm",
    "outputId": "dfbebca7-6508-4052-a0d3-829a2cc273c7"
   },
   "outputs": [],
   "source": [
    "# Making prediction\n",
    "user_id, prod_id, r_ui = \"A3LDPF5FMB782Z\", \"1400501466\", 5\n",
    "algo_svd.predict(user_id, prod_id, r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIjzqDY5nVNM"
   },
   "source": [
    "**Observations**\n",
    "- The svd base model offered a predicted rating of 4.26 against an actual rating of 5.\n",
    "- This is very good. However, further improvement can be made through hyperparameter tuning of the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1aYxVeMnVNM"
   },
   "source": [
    "**Below we are predicting rating for the `userId = \"A34BZM6S9L7QI4\"` and `productId = \"1400501466\"`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709520458878,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "APm-uMSvcAMf",
    "outputId": "a4063ee6-a7e9-47ed-866b-c70276795190"
   },
   "outputs": [],
   "source": [
    "# Making prediction\n",
    "user_id, prod_id = \"A34BZM6S9L7QI4\", \"1400501466\"\n",
    "algo_svd.predict(user_id, prod_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEL6dy3wnVNM"
   },
   "source": [
    "**Observations**\n",
    "- The svd base model makes a predicted rating of 4.43 on product the user has not interacted with based on the latent attributes of the user-item.\n",
    "- This is good. However, more improvement will be explored through hyperparameter tuning of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x13Eb9Owvpcw"
   },
   "source": [
    "### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQcDPhhcnVNN"
   },
   "source": [
    "Below we will be tuning only three hyperparameters:\n",
    "- **n_epochs**: The number of iterations of the SGD algorithm.\n",
    "- **lr_all**: The learning rate for all parameters.\n",
    "- **reg_all**: The regularization term for all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218649,
     "status": "ok",
     "timestamp": 1709520911685,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "4bM81V_hvtwv",
    "outputId": "1a1b9026-492a-45e2-ad83-92ad6fbd9b04"
   },
   "outputs": [],
   "source": [
    "# Set the parameter space to tune\n",
    "param_grid = {'n_epochs': [10, 20, 30],\n",
    "              'lr_all': [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007],\n",
    "              'reg_all': [0.01, 0.02, 0.03, 0.04, 0.06, 0.2, 0.4, 0.6]}\n",
    "\n",
    "# Performing 3-fold gridsearch cross-validation\n",
    "gs_svd = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Fitting data\n",
    "gs_svd.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "print(gs_svd.best_score['rmse'])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "best_params = gs_svd.best_params['rmse']\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzY78HsrnVNO"
   },
   "source": [
    "Now, we will **the build final model** by using **tuned values** of the hyperparameters, which we received using grid search cross-validation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1925,
     "status": "ok",
     "timestamp": 1709520913610,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "TA_7xe-nnhuu",
    "outputId": "6c7a6e63-6d30-428b-d41b-97a295a57ede"
   },
   "outputs": [],
   "source": [
    "# Build the optimized SVD model using optimal hyperparameter search. Use random_state=1\n",
    "n_epochs = best_params['n_epochs'] # extracted from best param dict\n",
    "lr_all = best_params['lr_all'] # extracted from best param dict\n",
    "reg_all = best_params['reg_all'] # extracted from best param dict\n",
    "\n",
    "algo_svd_optimized = SVD(n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all, random_state=1)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo_svd_optimized.fit(trainset)\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "print(\"svd base model metrics:\")\n",
    "precision_recall_at_k(algo_svd, testset)\n",
    "print(\"-\" * 20)\n",
    "print()\n",
    "\n",
    "print(\"optimized svd model metrics:\")\n",
    "precision_recall_at_k(algo_svd_optimized, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HJvPsjITsny"
   },
   "source": [
    "**Observations**\n",
    "- The svd base model could not be improved as the F_1 score produced lower value compared to the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuOTLnnUvSHD"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1709520913611,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "_4kghaW5vSHD",
    "outputId": "804310b6-b8de-4496-dd41-b28a0504b437"
   },
   "outputs": [],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "user_id, prod_id, r_ui = \"A3LDPF5FMB782Z\", \"1400501466\", 5\n",
    "algo_svd_optimized.predict(user_id, prod_id, r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1709520913611,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "8Rbh7qgFvSHD",
    "outputId": "a3dcae8e-4b18-466a-c726-a84028c246f6"
   },
   "outputs": [],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "user_id, prod_id, r_ui = \"A34BZM6S9L7QI4\", \"1400501466\", None\n",
    "algo_svd_optimized.predict(user_id, prod_id, r_ui, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2RniYu1BUbh"
   },
   "source": [
    "## Checking Metrics for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1709520913611,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "9DlNgZIXBXah"
   },
   "outputs": [],
   "source": [
    "# create function to display the metrics of an algorithm\n",
    "def display_algo_metrics(algo, name_):\n",
    "  print(f\"Metrics for {name_}:\")\n",
    "  precision_recall_at_k(algo, testset)\n",
    "  print(\"-\" * 20)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3750,
     "status": "ok",
     "timestamp": 1709520917360,
     "user": {
      "displayName": "Lucky Salomi",
      "userId": "06893108804487183708"
     },
     "user_tz": -60
    },
    "id": "WNo2HVDsCWss",
    "outputId": "01f27c53-797e-4670-e199-bc1583bf3301"
   },
   "outputs": [],
   "source": [
    "algos = {\"Optimized sim_user-user\": algo_knn_item_optimized,\n",
    "         \"Optimized sim_item-item\": algo_knn_item_optimized,\n",
    "         \"Base svd model\": algo_svd}\n",
    "\n",
    "for key, item in algos.items():\n",
    "  display_algo_metrics(item, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnwPwgjB8DwS"
   },
   "source": [
    "## **Conclusion and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuqnifw9NF2p"
   },
   "source": [
    "- Recommendation systems were builts using four different algorithms. They are as follows:\n",
    "  - Rank-based using averages-based popularity.\n",
    "  - User-user similarity-based collaborative filtering\n",
    "  - Item-item similarity-based collaborative filtering\n",
    "  - Model-based (matrix factorization) collaborative filtering.\n",
    "\n",
    "- Collaborative Filtering searches for neighbors based on similarity of products preferences and recommend products that those neighbors had purchased and rated while Matrix factorization works by decomposing the user-item matrix into the product of two lower dimensionality rectangular matrices.\n",
    "\n",
    "- To demonstrate **\"user-user similarity-based collaborative filtering\", \"item-item similarity-based collaborative filtering\", and \"model-based (matrix factorization) collaborative filtering\"**, **surprise** library has been used. For these algorithms, **grid search cross-validation is used to find the optimal hyperparameters for the data**, and improve the performance of the model**.\n",
    "\n",
    "- **For performance evaluation** of these models, **precision@k and recall@k** are used. Using these two metrics, the F_1 score is calculated for each working model. F1_score was used as an evaluation basis as we set out the objective to maximize the number of recommended products that are relevent (`recall`) and the number of relevant products that are recommended (`precision`).\n",
    "\n",
    "- Overall, the **matrix factorization** recommendation system** has given the **best performance** in terms of the F1-Score (~0.827).\n",
    "\n",
    "- Matrix Factorization has the lowest RMSE (~0.91) due to the reason that it assumes that both products and users are present in some low dimensional space describing their properties and recommend a product based on its proximity to the user in the latent space. Implying it accounts for latent factors as well.\n",
    "\n",
    "- We can try to further improve the performance of these models using hyperparameter tuning.\n",
    "\n",
    "- We can also try to combine different recommendation techniques to build a more complex model like hybrid recommendation systems."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
